# %%writefile app.py
import os, json, sys, hashlib
from pathlib import Path

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

from PIL import Image
import streamlit as st
import pandas as pd

# =========================
# Í≤ΩÎ°ú/Ï†ÑÏ≤òÎ¶¨
# =========================
try:
    BASE_DIR = Path(__file__).resolve().parent
except NameError:
    BASE_DIR = Path(os.getcwd()).resolve()

ARTIFACTS_DIR = BASE_DIR / "artifacts_3cls"
ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)

MODEL_PATH = ARTIFACTS_DIR / "resnet18_3cls_best.pth"
MAP_PATH   = ARTIFACTS_DIR / "class_to_idx.json"

IMG_EXTS = {".png", ".jpg", ".jpeg", ".bmp", ".webp", ".tif", ".tiff", ".gif", ".jfif"}
MEAN = (0.485, 0.456, 0.406)
STD  = (0.229, 0.224, 0.225)
INFER_TF = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(MEAN, STD),
])

# =========================
# ÎÇ¥Ïû• ÎùºÎ≤®Îßµ(ÌååÏùº ÏóÜÏùÑ Îïå ÏûêÎèô ÏÉùÏÑ±Ïö©)
# ÌïôÏäµ Ïãú ÏÇ¨Ïö©Ìïú Îß§ÌïëÍ≥º ÎèôÏùºÌï¥Ïïº Ìï©ÎãàÎã§!
# =========================
EMBEDDED_CLASS_TO_IDX = {
    "awl": 0,
    "knife": 1,
    "scissor": 2,
}

# =========================
# Ïú†Ìã∏
# =========================
def _get_secret_or_env(key: str, default: str = "") -> str:
    try:
        if key in st.secrets:
            return str(st.secrets[key]).strip()
    except Exception:
        pass
    return os.getenv(key, default).strip()

def _sha256sum(p: Path) -> str:
    h = hashlib.sha256()
    with p.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()

# =========================
# Îã§Ïö¥Î°úÎìú/ÌôïÎ≥¥
# =========================
def ensure_model_download():
    """Î™®Îç∏(.pth)Ïù¥ ÏóÜÏúºÎ©¥ Google DriveÏóêÏÑú gdownÏúºÎ°ú Îã§Ïö¥Î°úÎìú (Secrets/ENV: MODEL_FILE_ID)."""
    try:
        with st.sidebar.expander("üêû DEBUG (env/paths)", expanded=False):
            try:
                has_secret = "MODEL_FILE_ID" in st.secrets
            except Exception:
                has_secret = False
            st.write({
                "cwd": os.getcwd(),
                "python": sys.version,
                "BASE_DIR": str(BASE_DIR),
                "MODEL_PATH": str(MODEL_PATH),
                "MAP_PATH": str(MAP_PATH),
                "has_secret_MODEL_FILE_ID": has_secret,
                "env_MODEL_FILE_ID": bool(os.getenv("MODEL_FILE_ID")),
            })

        if MODEL_PATH.exists() and MODEL_PATH.stat().st_size > 0:
            st.sidebar.success(f"Î™®Îç∏ Ï°¥Ïû¨: {MODEL_PATH.name} ({MODEL_PATH.stat().st_size} bytes)")
            return

        MODEL_FILE_ID = _get_secret_or_env("MODEL_FILE_ID", "")
        if not MODEL_FILE_ID:
            raise RuntimeError("MODEL_FILE_IDÍ∞Ä ÎπÑÏñ¥ ÏûàÏäµÎãàÎã§. (Settings‚ÜíSecrets ÎòêÎäî ÌôòÍ≤ΩÎ≥ÄÏàòÎ°ú ÏÑ§Ï†ï)")

        try:
            import gdown
        except ImportError:
            import subprocess
            subprocess.check_call([sys.executable, "-m", "pip", "install", "gdown"])
            import gdown

        url = f"https://drive.google.com/uc?id={MODEL_FILE_ID}&export=download"
        tmp_path = MODEL_PATH.with_suffix(".downloading")
        ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)

        with st.spinner("Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ï§ë... (gdown)"):
            st.sidebar.write("üêû gdown url =", url)
            gdown.download(url, str(tmp_path), quiet=False)

        if not tmp_path.exists() or tmp_path.stat().st_size == 0:
            raise RuntimeError("Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ïã§Ìå®: ÌååÏùºÏù¥ ÎπÑÏóàÍ±∞ÎÇò ÏÉùÏÑ±ÎêòÏßÄ ÏïäÏùå (Í≥µÏú†Í∂åÌïú/FILE_ID ÌôïÏù∏)")

        expected_hash = _get_secret_or_env("MODEL_SHA256", "")
        if expected_hash:
            got = _sha256sum(tmp_path)
            if got.lower() != expected_hash.lower():
                tmp_path.unlink(missing_ok=True)
                raise RuntimeError(f"Î™®Îç∏ Ìï¥Ïãú Î∂àÏùºÏπò: got={got} expected={expected_hash}")

        tmp_path.rename(MODEL_PATH)
        st.sidebar.success(f"Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {MODEL_PATH} ({MODEL_PATH.stat().st_size} bytes)")

    except Exception as e:
        st.error(f"ensure_model_download() Ïã§Ìå®: {type(e).__name__}: {e}")
        st.info("Ï≤¥ÌÅ¨: SecretsÏùò MODEL_FILE_ID, ÎìúÎùºÏù¥Î∏å Í≥µÏú†(ÎßÅÌÅ¨ ÏûàÎäî Î™®Îì† ÏÇ¨Ïö©Ïûê), requirements.txtÏùò gdown")
        st.stop()

def ensure_label_map():
    """
    class_to_idx.json ÌôïÎ≥¥ Ïö∞ÏÑ†ÏàúÏúÑ:
    1) ÌååÏùºÏù¥ Ïù¥ÎØ∏ ÏûàÏúºÎ©¥ ÏÇ¨Ïö©
    2) MAP_FILE_IDÍ∞Ä ÏûàÏúºÎ©¥ ÎìúÎùºÏù¥Î∏åÏóêÏÑú Îã§Ïö¥Î°úÎìú
    3) Îëò Îã§ ÏïÑÎãàÎ©¥ EMBEDDED_CLASS_TO_IDXÎ°ú ÌååÏùº ÏÉùÏÑ±
    """
    if MAP_PATH.exists() and MAP_PATH.stat().st_size > 0:
        return

    MAP_FILE_ID = _get_secret_or_env("MAP_FILE_ID", "")
    if MAP_FILE_ID:
        try:
            import gdown
        except ImportError:
            import subprocess
            subprocess.check_call([sys.executable, "-m", "pip", "install", "gdown"])
            import gdown

        url = f"https://drive.google.com/uc?id={MAP_FILE_ID}&export=download"
        with st.spinner("ÎùºÎ≤® Îßµ Îã§Ïö¥Î°úÎìú Ï§ë... (gdown)"):
            gdown.download(url, str(MAP_PATH), quiet=False)

        if MAP_PATH.exists() and MAP_PATH.stat().st_size > 0:
            return
        else:
            st.warning("MAP_FILE_ID Îã§Ïö¥Î°úÎìú Ïã§Ìå®. ÎÇ¥Ïû• ÎùºÎ≤®ÎßµÏúºÎ°ú ÏÉùÏÑ±Ìï©ÎãàÎã§.")

    # ÎÇ¥Ïû• ÎùºÎ≤®ÎßµÏúºÎ°ú ÌååÏùº ÏÉùÏÑ±
    try:
        ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)
        with open(MAP_PATH, "w", encoding="utf-8") as f:
            json.dump(EMBEDDED_CLASS_TO_IDX, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"class_to_idx.json ÏÉùÏÑ± Ïã§Ìå®: {e}")
        st.stop()

# =========================
# Î°úÎìú
# =========================
@st.cache_resource
def load_model_and_labels(arch: str = "resnet18"):
    """(model, idx_to_class, class_to_idx) Î∞òÌôò."""
    ensure_model_download()
    ensure_label_map()

    # ÎùºÎ≤® Î°úÎìú
    try:
        with open(MAP_PATH, "r", encoding="utf-8") as f:
            class_to_idx = json.load(f)
    except Exception as e:
        st.error(f"class_to_idx.json Î°úÎìú Ïã§Ìå®: {e}")
        st.stop()

    idx_to_class = {v: k for k, v in class_to_idx.items()}
    num_classes = len(idx_to_class)

    # Î∞±Î≥∏ Íµ¨ÏÑ± (ÌïôÏäµÍ≥º ÎèôÏùº)
    if arch == "resnet18":
        backbone = models.resnet18(weights=None)
    elif arch == "resnet50":
        backbone = models.resnet50(weights=None)
    else:
        raise ValueError("Unsupported arch (resnet18|resnet50)")

    in_features = backbone.fc.in_features
    backbone.fc = nn.Linear(in_features, num_classes)  # Ìó§Îìú Íµ¨Ï°∞Í∞Ä ÌïôÏäµÍ≥º ÎèôÏùºÌï¥Ïïº Ìï®

    # Í∞ÄÏ§ëÏπò Î°úÎìú
    try:
        state = torch.load(MODEL_PATH, map_location="cpu")
        if isinstance(state, dict) and "state_dict" in state and isinstance(state["state_dict"], dict):
            backbone.load_state_dict(state["state_dict"], strict=True)
        elif isinstance(state, dict) and all(
            isinstance(k, str) and (
                k.startswith(("conv", "bn", "layer", "fc")) or "num_batches_tracked" in k
            ) for k in state.keys()
        ):
            backbone.load_state_dict(state, strict=True)
        else:
            try:
                backbone = state
                if hasattr(backbone, "eval"):
                    backbone.eval()
                else:
                    raise RuntimeError("Î∂àÏßÄÏõê ÌòïÏãù: Ï†ÑÏ≤¥ Î™®Îç∏ Í∞ùÏ≤¥Í∞Ä ÏïÑÎãò")
            except Exception as e:
                raise RuntimeError(f"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Î™®Îç∏ Ï†ÄÏû• ÌòïÏãùÏûÖÎãàÎã§: {e}")
    except Exception as e:
        st.error(f"Î™®Îç∏ Í∞ÄÏ§ëÏπò Î°úÎìú Ïã§Ìå®: {e}")
        st.stop()

    backbone.eval()
    return backbone, idx_to_class, class_to_idx

def predict_one(img: Image.Image, model: torch.nn.Module, device, idx_to_class: dict):
    x = INFER_TF(img).unsqueeze(0).to(device)
    with torch.no_grad():
        logits = model(x)
        prob = F.softmax(logits, dim=1)[0].detach().cpu().numpy()
    items = [(idx_to_class[i], float(prob[i])) for i in range(len(prob))]
    items.sort(key=lambda t: t[1], reverse=True)
    return items, prob

# =========================
# UI
# =========================
st.set_page_config(page_title="Knife/Awl/Scissor Classifier", page_icon="üîé", layout="centered")
st.title("üîé 3-Class Classifier (ResNet)")
st.caption("knife / awl / scissor ‚Äî ÌôïÎ•† ÏòàÏ∏° Îç∞Î™®")

with st.sidebar.expander("üîç Debug (secrets/env quick)", expanded=False):
    try:
        has_secret = "MODEL_FILE_ID" in st.secrets
    except Exception:
        has_secret = False
    st.write("has st.secrets['MODEL_FILE_ID']:", has_secret)
    st.write("env MODEL_FILE_ID set:", bool(os.getenv("MODEL_FILE_ID")))
    st.write("MODEL_PATH exists:", MODEL_PATH.exists())
    if MODEL_PATH.exists():
        st.write("MODEL_PATH size:", MODEL_PATH.stat().st_size)
with st.sidebar.expander("üîç Label map check", expanded=False):
    st.write("MAP_PATH:", str(MAP_PATH))
    st.write("MAP exists:", MAP_PATH.exists())
    if MAP_PATH.exists():
        st.write("MAP size:", MAP_PATH.stat().st_size)
        try:
            with open(MAP_PATH, "r", encoding="utf-8") as f:
                jm = json.load(f)
            st.success(f"class_to_idx loaded. num_classes = {len(jm)} ‚Üí keys: {list(jm.keys())}")
        except Exception as e:
            st.error(f"Failed to read class_to_idx.json: {e}")

# (ÏòµÏÖò) Secrets ÏóÜÏù¥ ÌÖåÏä§Ìä∏ Ïãú ÏûÑÏãú ÏûÖÎ†•
if _get_secret_or_env("MODEL_FILE_ID", "") == "":
    with st.sidebar.expander("‚ö†Ô∏è Set MODEL_FILE_ID (temp)", expanded=False):
        tmp_id = st.text_input("Google Drive FILE_ID")
        if tmp_id:
            os.environ["MODEL_FILE_ID"] = tmp_id
            st.success("MODEL_FILE_ID set for this session. Rerun the app (‚åò/Ctrl+R).")

with st.spinner("Î™®Îç∏ Î°úÎî© Ï§ë..."):
    model, idx_to_class, class_to_idx = load_model_and_labels(arch="resnet18")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

tab1, tab2 = st.tabs(["üìÑ Îã®Ïùº Ïù¥ÎØ∏ÏßÄ", "üìÅ Ïó¨Îü¨ Ïù¥ÎØ∏ÏßÄ(Î∞∞Ïπò)"])

with tab1:
    up = st.file_uploader("Ïù¥ÎØ∏ÏßÄ ÏóÖÎ°úÎìú", type=[ext.lstrip(".") for ext in IMG_EXTS])
    conf_th = st.slider("ÌëúÏãú ÏûÑÍ≥ÑÍ∞í(threshold)", 0.0, 1.0, 0.0, 0.01)
    if up is not None:
        try:
            img = Image.open(up).convert("RGB")
            st.image(img, caption="ÏûÖÎ†• Ïù¥ÎØ∏ÏßÄ", use_container_width=True)
            items, prob = predict_one(img, model, device, idx_to_class)

            df = pd.DataFrame([{"class": c, "prob": p} for c, p in items])
            st.subheader("ÌôïÎ•†")
            st.bar_chart(df.set_index("class"))

            top1 = items[0]
            st.markdown(f"**Top-1:** `{top1[0]}` ‚Äî **{top1[1]*100:.2f}%**")
            label = top1[0] if top1[1] >= conf_th else "unknown"
            st.markdown(f"**ÏµúÏ¢Ö ÎùºÎ≤®(ÏûÑÍ≥ÑÍ∞í {conf_th:.2f}):** `{label}`")
        except Exception as e:
            st.error(f"Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}")

with tab2:
    ups = st.file_uploader("Ïó¨Îü¨ Ïù¥ÎØ∏ÏßÄ ÏóÖÎ°úÎìú", type=[ext.lstrip(".") for ext in IMG_EXTS], accept_multiple_files=True)
    if ups:
        rows = []
        for f in ups:
            try:
                img = Image.open(f).convert("RGB")
                items, prob = predict_one(img, model, device, idx_to_class)
                top1 = items[0]
                row = {"filename": f.name, "pred": top1[0], "conf": top1[1]}
                for cls in sorted(class_to_idx, key=lambda k: class_to_idx[k]):
                    idx = class_to_idx[cls]
                    row[f"p_{cls}"] = float(prob[idx])
                rows.append(row)
            except Exception as e:
                rows.append({"filename": f.name, "pred": "ERROR", "conf": 0.0, "error": str(e)})

        if rows:
            out_df = pd.DataFrame(rows)
            st.dataframe(out_df, use_container_width=True)
            st.download_button(
                "CSV Îã§Ïö¥Î°úÎìú",
                data=out_df.to_csv(index=False).encode("utf-8"),
                file_name="infer_results.csv",
                mime="text/csv",
            )
