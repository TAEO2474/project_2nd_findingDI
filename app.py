import os, json
from pathlib import Path

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

from PIL import Image
import streamlit as st
import pandas as pd

# =========================
# ê¸°ë³¸ ê²½ë¡œ/ì „ì²˜ë¦¬ ì„¤ì •
# =========================
BASE_DIR = Path(os.getcwd()) # Use current working directory instead
MODEL_PATH = BASE_DIR / "artifacts_3cls" / "resnet18_3cls_best.pth"     # ëª¨ë¸ íŒŒì¼ì€ ëŸ°íƒ€ì„ì— gdownìœ¼ë¡œ ë°›ìŒ
MAP_PATH   = BASE_DIR / "artifacts_3cls" / "class_to_idx.json"          # ë ˆí¬ì— ìˆìœ¼ë©´ ë°”ë¡œ ì‚¬ìš©

IMG_EXTS = {".png", ".jpg", ".jpeg", ".bmp", ".webp", ".tif", ".tiff", ".gif", ".jfif"}
MEAN = (0.485, 0.456, 0.406)
STD  = (0.229, 0.224, 0.225)
INFER_TF = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(MEAN, STD),
])

# =========================
# ëª¨ë¸/ë¼ë²¨ ì¤€ë¹„ (ë‹¤ìš´ë¡œë“œ + ë¡œë“œ)
# =========================
def ensure_model_download():
    """
    Google Drive ê³µìœ  ë§í¬ì˜ FILE_IDë¥¼ ë„£ì–´ë‘ë©´, ëª¨ë¸(.pth)ì´ ì—†ì„ ë•Œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    - ë§í¬ ê³µìœ  ê¶Œí•œ: 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì ë³´ê¸°/ë‹¤ìš´ë¡œë“œ' í•„ìˆ˜
    """
    if MODEL_PATH.exists():
        return

    # TODO: ì•„ë˜ FILE_IDë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”.
    MODEL_FILE_ID = "FILE_ID"  # ì˜ˆ: 1AbCdEfGhIJ... (drive.google.com/file/d/ì—¬ê¸°ë¶€ë¶„/view)
    if MODEL_FILE_ID == "FILE_ID":
        st.error(
            "ëª¨ë¸(.pth) íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            f"- ê¸°ëŒ€ ê²½ë¡œ: {MODEL_PATH}\n"
            "- Google Drive FILE_IDë¥¼ app.py ìƒë‹¨ ensure_model_download() ì•ˆì— ì„¤ì •í•´ ì£¼ì„¸ìš”."
        )
        st.stop()

    try:
        import gdown
    except ImportError:
        st.error("gdownì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirements.txtì— gdownì„ í¬í•¨í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    url = f"https://drive.google.com/uc?id={MODEL_FILE_ID}&export=download"
    with st.spinner("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (gdown)"):
        gdown.download(url, str(MODEL_PATH), quiet=False)

    if not MODEL_PATH.exists():
        st.error("ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê³µìœ  ì„¤ì •ê³¼ FILE_IDë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

def ensure_label_map():
    """
    class_to_idx.jsonì´ ë ˆí¬ì— ì—†ìœ¼ë©´(ì„ íƒ) Google Driveì—ì„œ ë°›ì•„ì˜µë‹ˆë‹¤.
    í•„ìš” ì—†ë‹¤ë©´ ì•„ë˜ MAP_FILE_ID ë¶€ë¶„ì„ 'FILE_ID_JSON' ê·¸ëŒ€ë¡œ ë‘ê³ ,
    ë ˆí¬ì— class_to_idx.json íŒŒì¼ì„ ì˜¬ë ¤ë‘ì„¸ìš”.
    """
    if MAP_PATH.exists():
        return

    # (ì„ íƒ) JSONë„ ë“œë¼ì´ë¸Œì—ì„œ ë°›ê¸° ì›í•˜ë©´ FILE_ID_JSON ì„¤ì •í•˜ì„¸ìš”.
    MAP_FILE_ID = "FILE_ID_JSON"  # ì˜ˆ: 1XyZ...
    if MAP_FILE_ID == "FILE_ID_JSON":
        st.error(
            "`class_to_idx.json`ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            f"- ê¸°ëŒ€ ê²½ë¡œ: {MAP_PATH}\n"
            "- ë ˆí¬ì— íŒŒì¼ì„ ì¶”ê°€í•˜ê±°ë‚˜, ensure_label_map()ì˜ MAP_FILE_IDë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”."
        )
        st.stop()

    try:
        import gdown
    except ImportError:
        st.error("gdownì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirements.txtì— gdownì„ í¬í•¨í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    url = f"https://drive.google.com/uc?id={MAP_FILE_ID}&export=download"
    with st.spinner("ë¼ë²¨ ë§µ ë‹¤ìš´ë¡œë“œ ì¤‘... (gdown)"):
        gdown.download(url, str(MAP_PATH), quiet=False)

    if not MAP_PATH.exists():
        st.error("ë¼ë²¨ ë§µ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê³µìœ  ì„¤ì •ê³¼ FILE_ID_JSONì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()


@st.cache_resource
def load_model_and_labels(arch: str = "resnet18"):
    """ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ í´ë˜ìŠ¤ ë§¤í•‘ì„ ë¡œë“œí•˜ê³ , (model, idx_to_class, class_to_idx)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    ensure_model_download()
    ensure_label_map()

    # ë¼ë²¨ ë¡œë“œ
    with open(MAP_PATH, "r", encoding="utf-8") as f:
        class_to_idx = json.load(f)
    idx_to_class = {v: k for k, v in class_to_idx.items()}
    num_classes = len(idx_to_class)

    # ë°±ë³¸ êµ¬ì„± (í•™ìŠµ ë•Œì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤)
    if arch == "resnet18":
        backbone = models.resnet18(weights=None)
    elif arch == "resnet50":
        backbone = models.resnet50(weights=None)
    else:
        raise ValueError("Unsupported arch (resnet18|resnet50)")

    in_features = backbone.fc.in_features

    # âš ï¸ í•™ìŠµ ì‹œ MLP í—¤ë“œë¥¼ ì¼ë‹¤ë©´ ì•„ë˜ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤.
    # ì˜ˆ) Linear â†’ ReLU â†’ Dropout â†’ Linear ì˜€ë‹¤ë©´ ê°™ì€ êµ¬ì¡°ë¡œ êµì²´ í•„ìš”.
    # í˜„ì¬ëŠ” ë‹¨ì¼ Linearë¡œ ê°€ì • (resnet18_3cls_best.pth ì €ì¥ ì‹œì ê³¼ ì¼ì¹˜)
    backbone.fc = nn.Linear(in_features, num_classes)

    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    state = torch.load(MODEL_PATH, map_location="cpu")
    backbone.load_state_dict(state, strict=True)
    backbone.eval()
    return backbone, idx_to_class, class_to_idx

def predict_one(img: Image.Image, model: torch.nn.Module, device, idx_to_class: dict):
    x = INFER_TF(img).unsqueeze(0).to(device)
    with torch.no_grad():
        logits = model(x)
        prob = F.softmax(logits, dim=1)[0].detach().cpu().numpy()
    items = [(idx_to_class[i], float(prob[i])) for i in range(len(prob))]
    items.sort(key=lambda t: t[1], reverse=True)
    return items, prob

# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="Knife/Awl/Scissor Classifier", page_icon="ğŸ”", layout="centered")
st.title("ğŸ” 3-Class Classifier (ResNet)")
st.caption("knife / awl / scissor â€” í™•ë¥  ì˜ˆì¸¡ ë°ëª¨")

with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
    model, idx_to_class, class_to_idx = load_model_and_labels(arch="resnet18")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

tab1, tab2 = st.tabs(["ğŸ“„ ë‹¨ì¼ ì´ë¯¸ì§€", "ğŸ“ ì—¬ëŸ¬ ì´ë¯¸ì§€(ë°°ì¹˜)"])

with tab1:
    up = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=[ext.lstrip(".") for ext in IMG_EXTS])
    conf_th = st.slider("í‘œì‹œ ì„ê³„ê°’(threshold)", 0.0, 1.0, 0.0, 0.01)
    if up is not None:
        try:
            img = Image.open(up).convert("RGB")
            st.image(img, caption="ì…ë ¥ ì´ë¯¸ì§€", use_column_width=True)
            items, prob = predict_one(img, model, device, idx_to_class)

            df = pd.DataFrame([{"class": c, "prob": p} for c, p in items])
            st.subheader("í™•ë¥ ")
            st.bar_chart(df.set_index("class"))

            top1 = items[0]
            st.markdown(f"**Top-1:** `{top1[0]}` â€” **{top1[1]*100:.2f}%**")
            label = top1[0] if top1[1] >= conf_th else "unknown"
            st.markdown(f"**ìµœì¢… ë¼ë²¨(ì„ê³„ê°’ {conf_th:.2f}):** `{label}`")
        except Exception as e:
            st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

with tab2:
    ups = st.file_uploader("ì—¬ëŸ¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=[ext.lstrip(".") for ext in IMG_EXTS], accept_multiple_files=True)
    if ups:
        rows = []
        for f in ups:
            try:
                img = Image.open(f).convert("RGB")
                items, prob = predict_one(img, model, device, idx_to_class)
                top1 = items[0]
                row = {"filename": f.name, "pred": top1[0], "conf": top1[1]}
                # ê³ ì • ìˆœì„œ: class_to_idxì˜ ì¸ë±ìŠ¤ ìˆœ
                for cls in sorted(class_to_idx, key=lambda k: class_to_idx[k]):
                    idx = class_to_idx[cls]
                    row[f"p_{cls}"] = float(prob[idx])
                rows.append(row)
            except Exception as e:
                rows.append({"filename": f.name, "pred": "ERROR", "conf": 0.0, "error": str(e)})

        if rows:
            out_df = pd.DataFrame(rows)
            st.dataframe(out_df, use_container_width=True)
            st.download_button(
                "CSV ë‹¤ìš´ë¡œë“œ",
                data=out_df.to_csv(index=False).encode("utf-8"),
                file_name="infer_results.csv",
                mime="text/csv",
            )
